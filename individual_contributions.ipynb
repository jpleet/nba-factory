{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76d4401-9177-4fe2-9764-81803bb2a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp\n",
    "from wurlitzer import pipes, STDOUT\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import xlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835089ad-accd-4127-8b73-eac9952e70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.001, 0.0001]\n",
    "sample_prcts = [0.7] #[0.7, 0.75, 0.8]\n",
    "sample_params = [{'epsilon' : e, 'sample_prct' : s} for e in epsilons for s in sample_prcts] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84622ca2-7cbd-46fb-bcf2-e7aaf1566784",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.01] #[0.01, 0.02, 0.05, 0.075, 0.1, 0.15, 0.2]\n",
    "lmbs = [0.0001] #[0.00002, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "ks = [3] #[2, 3, 4]\n",
    "train_params = [{'task' : 'reg', 'init' : 0.1, 'lr' : lr, 'lambda' : lmb, 'k' : k} \n",
    "                for lr in lrs for lmb in lmbs for k in ks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544a40dd-1024-45e9-87cb-7fba6347e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_season(season, base_folder = 'data/lineup'):\n",
    "    \n",
    "    print(season)\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    # load all season lineups\n",
    "    mat, target, player_df = _create_sparse_data(season, base_folder)\n",
    "    \n",
    "    # sample data\n",
    "    for sample_param in tqdm(sample_params):\n",
    "        \n",
    "        sample_prct = sample_param['sample_prct']\n",
    "        epsilon = sample_param['epsilon']\n",
    "            \n",
    "        rand_idx = target.sample(int(sample_prct * len(target)), \n",
    "                                 replace=False, weights=target+epsilon).index.values\n",
    "\n",
    "        predict_file = f'/tmp/nba_predict.txt'\n",
    "        dump_svmlight_file(sp.eye(len(player_df)*2), [1]*(len(player_df)*2), predict_file)\n",
    "\n",
    "        train_file = f'/tmp/nba_train.txt'\n",
    "        dump_svmlight_file(mat[rand_idx], target[rand_idx], train_file)\n",
    "        \n",
    "        for train_param in train_params:\n",
    "            \n",
    "            fm = xlearn.create_fm()\n",
    "            fm.setTrain(train_file)\n",
    "\n",
    "            out = io.StringIO()\n",
    "            with pipes(stdout=out, stderr=STDOUT):\n",
    "                fm.cv(train_param)\n",
    "            out_val = out.getvalue()\n",
    "            cv_mse = float(out_val.split('Average mse_loss:')[1].split('\\n')[0].strip())            \n",
    "            \n",
    "            fm = xlearn.create_fm()\n",
    "            fm.setTrain(train_file)\n",
    "            fm.setTXTModel(f'/tmp/nba_model.txt')\n",
    "\n",
    "            out = io.StringIO()\n",
    "            with pipes(stdout=out, stderr=STDOUT):\n",
    "                fm.fit(train_param, f'/tmp/nba_model.out')\n",
    "            full_out_val = out.getvalue()\n",
    "            \n",
    "            # run prediction\n",
    "            fm = xlearn.create_fm()\n",
    "            fm.setTest(predict_file)\n",
    "            # make predictions\n",
    "            pred_file = '/tmp/nba_mod_predict.txt'\n",
    "            out = io.StringIO()\n",
    "            with pipes(stdout=out, stderr=STDOUT):\n",
    "                fm.predict(f'/tmp/nba_model.out', pred_file)\n",
    "\n",
    "            pred_df = pd.DataFrame()\n",
    "            pred_values = []\n",
    "            with open(pred_file) as f:\n",
    "                for line in f:\n",
    "                    pred_values.append(float(line.replace('\\n', '')))\n",
    "            pred_df['predict'] = pred_values\n",
    "            pred_df['LAT_ID'] = np.arange(len(pred_df))\n",
    "            \n",
    "            player_pred = player_df.copy()\n",
    "            player_pred = player_pred.merge(pred_df.rename(columns={'LAT_ID' : 'off_id', \n",
    "                                                                    'predict' : 'off_pred'}), on='off_id')\n",
    "            player_pred = player_pred.merge(pred_df.rename(columns={'LAT_ID' : 'def_id', \n",
    "                                                                    'predict' : 'def_pred'}), on='def_id')\n",
    "            \n",
    "            player_pred['off_norm'] = (player_pred.off_pred - player_pred.off_pred.mean()) / player_pred.off_pred.std()\n",
    "            player_pred['def_norm'] = (player_pred.def_pred - player_pred.def_pred.mean()) / player_pred.def_pred.std()\n",
    "            player_pred['cv_mse'] = cv_mse\n",
    "            \n",
    "            all_preds.append(player_pred)\n",
    "            \n",
    "    \n",
    "    [os.remove(f) for f in glob('/tmp/nba*')]\n",
    "    \n",
    "    all_preds = pd.concat(all_preds, ignore_index=True)\n",
    "    \n",
    "    preds_grp = []\n",
    "    for person_id, g in all_preds.groupby('person_id'):\n",
    "        off_norm = np.average(g.off_norm, weights=1/g.cv_mse)\n",
    "        def_norm = np.average(g.def_norm, weights=1/g.cv_mse)\n",
    "        time = g.time.iloc[0]\n",
    "        preds_grp.append([person_id, time, off_norm, def_norm])\n",
    "    preds_grp = pd.DataFrame(preds_grp, columns=['person_id', 'time', 'off_norm', 'def_norm'])\n",
    "    \n",
    "    all_players = _get_player_info(season)\n",
    "    \n",
    "    res = all_players.merge(preds_grp, on='person_id')\n",
    "    \n",
    "    return res\n",
    "            \n",
    "def _create_sparse_data(season, base_folder):\n",
    "    df = pd.concat([pd.read_csv(f) for f in glob(f'{base_folder}/{season}/*.csv')], ignore_index=True)\n",
    "    df['time'] = df.end - df.start   \n",
    "    \n",
    "    # group lineups \n",
    "    data = []\n",
    "    for k,g in df.groupby(['h1', 'h2', 'h3', 'h4', 'h5', 'v1', 'v2', 'v3', 'v4', 'v5']):\n",
    "        data.append(k + (g.home_points.sum(), g.visit_points.sum(), g.time.sum()))\n",
    "    data = pd.DataFrame(data, columns=['h1', 'h2', 'h3', 'h4', 'h5', 'v1', 'v2', 'v3', 'v4', 'v5', \n",
    "                                       'home_points', 'visit_points', 'time'])\n",
    "    \n",
    "    # get player ids\n",
    "    player_df = _get_player_df(data)\n",
    "    \n",
    "    # add sparse id to lineups\n",
    "    new_ids = [('h1', 'off'), ('h2', 'off'), ('h3', 'off'), ('h4', 'off'), ('h5', 'off'), \n",
    "               ('v1', 'off'), ('v2', 'off'), ('v3', 'off'), ('v4', 'off'), ('v5', 'off'), \n",
    "               ('h1', 'def'), ('h2', 'def'), ('h3', 'def'), ('h4', 'def'), ('h5', 'def'), \n",
    "               ('v1', 'def'), ('v2', 'def'), ('v3', 'def'), ('v4', 'def'), ('v5', 'def')]\n",
    "    for i, p in new_ids:\n",
    "        data = _add_sparse_id(data, player_df, i, p)\n",
    "        \n",
    "    data['home_per_time'] = data.home_points / data.time\n",
    "    data['visit_per_time'] = data.visit_points / data.time\n",
    "    \n",
    "    data_home = data[['h1_off', 'h2_off', 'h3_off', 'h4_off', 'h5_off', \n",
    "                      'v1_def', 'v2_def', 'v3_def', 'v4_def', 'v5_def', 'home_per_time']].copy()\n",
    "    data_home['is_home'] = 1\n",
    "    data_visit = data[['v1_off', 'v2_off', 'v3_off', 'v4_off', 'v5_off', \n",
    "                       'h1_def', 'h2_def', 'h3_def', 'h4_def', 'h5_def', 'visit_per_time']].copy()\n",
    "    data_visit['is_home'] = 0\n",
    "    \n",
    "    data_home.columns = ['off1', 'off2', 'off3', 'off4', 'off5', \n",
    "                         'def1', 'def2', 'def3', 'def4', 'def5',\n",
    "                         'points_per_time', 'is_home']\n",
    "    data_visit.columns = ['off1', 'off2', 'off3', 'off4', 'off5', \n",
    "                          'def1', 'def2', 'def3', 'def4', 'def5', \n",
    "                          'points_per_time', 'is_home']\n",
    "    \n",
    "    data = pd.concat([data_home, data_visit], ignore_index=True)\n",
    "    \n",
    "    data.dropna(inplace=True)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # create sparse matrix\n",
    "    \n",
    "    target = data.points_per_time\n",
    "\n",
    "    cols= data[['off1', 'off2', 'off3', 'off4', 'off5', \n",
    "                'def1', 'def2', 'def3', 'def4', 'def5']].stack()\n",
    "    rows = cols.index.get_level_values(0)\n",
    "    z = [1] * len(rows)\n",
    "    \n",
    "    mat = sp.csr_matrix((z,(rows, cols)),shape=(len(data), len(player_df)*2))\n",
    "    \n",
    "    return mat, target, player_df\n",
    "\n",
    "def _get_player_df(data):\n",
    "\n",
    "    player_df = pd.DataFrame()\n",
    "    player_df['person_id'] = data[['h1', 'h2', 'h3', 'h4', 'h5', \n",
    "                                   'v1', 'v2', 'v3', 'v4', 'v5']].unstack().unique()\n",
    "\n",
    "    player_time = pd.DataFrame()\n",
    "    player_time['person_id'] =  data[['h1', 'h2', 'h3', 'h4', 'h5', \n",
    "                                      'v1', 'v2', 'v3', 'v4', 'v5']].stack().values\n",
    "    player_time['time'] = np.repeat(data.time.values, 10)\n",
    "    player_time = player_time.groupby('person_id').time.sum().reset_index()\n",
    "\n",
    "    player_df = player_df.merge(player_time, on = 'person_id')\n",
    "\n",
    "    player_df['off_id'] = np.arange(len(player_df))\n",
    "    player_df['def_id'] = np.arange(len(player_df)) + len(player_df)\n",
    "    \n",
    "    return player_df\n",
    "\n",
    "def _add_sparse_id(data, player_df, ind, pos):\n",
    "    data = data.merge(player_df[[f'{pos}_id', 'person_id']].rename(columns={'person_id' : ind, \n",
    "                                                                            f'{pos}_id' : f'{ind}_{pos}'}), \n",
    "                      on=ind, how='left')\n",
    "    return data\n",
    "\n",
    "def _get_player_info(season):\n",
    "    rot_files = glob(f'data/nba-api/rotation/{season}/*.csv')\n",
    "    \n",
    "    all_players = []\n",
    "    for rot_file in tqdm(rot_files):\n",
    "        r = pd.read_csv(rot_file)\n",
    "        player = r[['TEAM_NAME', 'PERSON_ID', 'PLAYER_FIRST', 'PLAYER_LAST']].drop_duplicates()\n",
    "        all_players.append(player)\n",
    "    all_players = pd.concat(all_players, ignore_index=True).drop_duplicates()\n",
    "    all_players.reset_index(inplace=True, drop=True)\n",
    "    all_players.columns = [c.lower() for c in all_players.columns]\n",
    "    all_players['player_name'] = all_players.player_first + ' ' + all_players.player_last\n",
    "    \n",
    "    return all_players\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def create_plot(res):\n",
    "    \n",
    "    fig = go.Figure(go.Scatter(x = res['off_norm'], \n",
    "                               y = res['def_norm'], \n",
    "                               mode = 'markers', \n",
    "                               marker = {'size' : res['time']/5000},\n",
    "                               customdata = (res['time']/60).round(),\n",
    "                               hovertemplate = ('<b>%{hovertext}</b><br>' +\n",
    "                                                'Off : %{x:.2f}<br>' +\n",
    "                                                'Def : %{y:.2f}<br>' +\n",
    "                                                'Minutes : %{customdata}' + \n",
    "                                                '<extra></extra>'),\n",
    "                               hovertext = res['player_name']))\n",
    "\n",
    "    fig.update_layout(title={'text': season,\n",
    "                             'y':0.98, 'x':0.5, \n",
    "                             'xanchor': 'center', 'yanchor': 'top'},\n",
    "                      autosize = True,\n",
    "                      xaxis = dict(title = 'Offensive PPM'), \n",
    "                      yaxis = dict(title = 'Defensive PPM'))\n",
    "\n",
    "    fig.add_vline(x=res['off_norm'].mean(), line_width=2, line_dash=\"dash\", line_color=\"red\")\n",
    "    fig.add_hline(y=res['def_norm'].mean(), line_width=2, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "    buttons = [dict(method='update',\n",
    "                    label='All',\n",
    "                    args=[{'x': [res['off_norm']],\n",
    "                           'y': [res['def_norm']],\n",
    "                           'customdata' : [(res['time']/60).round()],\n",
    "                           'hovertext' : [res['player_name']],\n",
    "                           'marker' : [{'size' : res['time']/5000, \n",
    "                                        'text' : res['player_name']}]}])]\n",
    "\n",
    "    for team in res.team_name.unique():\n",
    "\n",
    "        buttons.append(dict(method='update',\n",
    "                            label=team,\n",
    "                            args=[{'x': [res.loc[res.team_name==team, 'off_norm']],\n",
    "                                   'y': [res.loc[res.team_name==team, 'def_norm']],\n",
    "                                   'customdata' : [(res.loc[res.team_name==team, 'time']/60).round()],\n",
    "                                   'hovertext' : [res.loc[res.team_name==team, 'player_name']],\n",
    "                                   'marker' : [{'size' : res.loc[res.team_name==team, 'time']/5000, \n",
    "                                                'text' : res.loc[res.team_name==team, 'player_name']}]}]))\n",
    "\n",
    "\n",
    "    fig.update_layout(updatemenus=[dict(buttons=buttons, direction='down', x=0.1, y=1.1, showactive=True)])    \n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df41b75c-73bb-4582-ae81-30ebf6986fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997-98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.33s/it]\n",
      "100%|██████████████████████████████████████| 1189/1189 [00:02<00:00, 402.73it/s]\n"
     ]
    }
   ],
   "source": [
    "season = '1997-98'\n",
    "res = process_season(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79c282b-0dda-4bb8-b88f-5ba5373d85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_plot(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
